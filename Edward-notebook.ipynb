{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edward源代码分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那个inference对象的run封装了调用initialize生成计算图和迭代update的操作。\n",
    "对于klqp来说，它的update,initialize逻辑继承自variational_inference。\n",
    "其中update的核心逻辑是调用已生成的\n",
    "计算图的优化op，该op是在initialize调用build_loss_and_gradients生成的。\n",
    "这个方法在klqp被重载，绑定到该模块几个核心函数上了。\n",
    "分别是对不同的概率结构生成不同的计算图。其中最一般的就是\n",
    "build_score_loss_and_gradients方法。不过其实所有方法其实都用了Monte Carlo采样\n",
    "\n",
    "贝叶斯模型虽然参数是随机变量，但如果参数的随机变量的分布又全是随机变量\n",
    "就没完没了了。于是终究在超参数阶段归于确定参数。\n",
    "那贝叶斯推断又在推断什么呢？既然我们已经以超参数给出了参数的分布？\n",
    "\n",
    "给出的参数分布与之后它们怎么影响隐变量又怎么影响可观测变量的所有关系，\n",
    "合成了联合分布函数或联合似然函数。那么我们就可以以可观测变量去预测\n",
    "参数随机变量或隐状态的取值，就像X先在[0,1]均匀取一个值，\n",
    "然后以此值为中心，加上噪声再生成10个值一样。这个模型本身是个联合分布，\n",
    "给定数据后当然有信息可以推断出中心的分布。而此处设定时那个分布其实是\n",
    "参数的先验分布，我们本来就是按参数的先验分布，给定参数时隐状态的条件分布，\n",
    "给定隐状态和参数时可观测变量的条件分布来描述联合分布而不是直接给出联合分布的。\n",
    "当然从推断的角度说，直接在先验分布上求极大似然或均值没什么意义，\n",
    "因为这个分布终究会被条件分布和数据冲掉。\n",
    "\n",
    "var_list里存的是qx式变量的超参数，优化过程比较隐晦，最重要的逻辑隐藏在\n",
    "闷身发大财的copy函数，这个copy做了dict_swap变换计算图，才能使得数据\n",
    "能够被引入，参数能够被优化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构造计算图的核心代码是\n",
    "\n",
    "\n",
    "```\n",
    "def build_score_loss_and_gradients(inference, var_list):\n",
    "  \"\"\"Build loss function and gradients based on the score function\n",
    "  estimator (Paisley et al., 2012).\n",
    "\n",
    "  Computed by sampling from :math:`q(z;\\lambda)` and evaluating the\n",
    "  expectation using Monte Carlo sampling.\n",
    "  \"\"\"\n",
    "  p_log_prob = [0.0] * inference.n_samples\n",
    "  q_log_prob = [0.0] * inference.n_samples\n",
    "  for s in range(inference.n_samples):\n",
    "    # Form dictionary in order to replace conditioning on prior or\n",
    "    # observed variable with conditioning on a specific value.\n",
    "    scope = 'inference_' + str(id(inference)) + '/' + str(s)\n",
    "    dict_swap = {}\n",
    "    for x, qx in six.iteritems(inference.data):\n",
    "      if isinstance(x, RandomVariable):\n",
    "        if isinstance(qx, RandomVariable):\n",
    "          qx_copy = copy(qx, scope=scope)\n",
    "          dict_swap[x] = qx_copy.value()\n",
    "        else:\n",
    "          dict_swap[x] = qx\n",
    "\n",
    "    for z, qz in six.iteritems(inference.latent_vars):\n",
    "      # Copy q(z) to obtain new set of posterior samples.\n",
    "      qz_copy = copy(qz, scope=scope)\n",
    "      dict_swap[z] = qz_copy.value()\n",
    "      q_log_prob[s] += tf.reduce_sum(\n",
    "          inference.scale.get(z, 1.0) *\n",
    "          qz_copy.log_prob(tf.stop_gradient(dict_swap[z])))\n",
    "\n",
    "    for z in six.iterkeys(inference.latent_vars):\n",
    "      z_copy = copy(z, dict_swap, scope=scope)\n",
    "      p_log_prob[s] += tf.reduce_sum(\n",
    "          inference.scale.get(z, 1.0) * z_copy.log_prob(dict_swap[z]))\n",
    "\n",
    "    for x in six.iterkeys(inference.data):\n",
    "      if isinstance(x, RandomVariable):\n",
    "        x_copy = copy(x, dict_swap, scope=scope)\n",
    "        p_log_prob[s] += tf.reduce_sum(\n",
    "            inference.scale.get(x, 1.0) * x_copy.log_prob(dict_swap[x]))\n",
    "\n",
    "  p_log_prob = tf.stack(p_log_prob)\n",
    "  q_log_prob = tf.stack(q_log_prob)\n",
    "\n",
    "  if inference.logging:\n",
    "    summary_key = 'summaries_' + str(id(inference))\n",
    "    tf.summary.scalar(\"loss/p_log_prob\", tf.reduce_mean(p_log_prob),\n",
    "                      collections=[summary_key])\n",
    "    tf.summary.scalar(\"loss/q_log_prob\", tf.reduce_mean(q_log_prob),\n",
    "                      collections=[summary_key])\n",
    "\n",
    "  losses = p_log_prob - q_log_prob\n",
    "  loss = -tf.reduce_mean(losses)\n",
    "\n",
    "  grads = tf.gradients(\n",
    "      -tf.reduce_mean(q_log_prob * tf.stop_gradient(losses)),\n",
    "      var_list)\n",
    "  grads_and_vars = list(zip(grads, var_list))\n",
    "  return loss, grads_and_vars\n",
    "\n",
    "```\n",
    "\n",
    "其中`var_list`是近似分布的超参数，被优化的tensorflow变量。`inference.data`是构建inference时传入的data字典，其key是模型（可观测）变量，\n",
    "value是对应的数据。而`inference.latent_vars`是构建inference时传入的latent_vars字典（第一个参数），其指定了对哪些变量求近似后验分布,\n",
    "key是原模型的变量，value是近似分布的变量。\n",
    "\n",
    "这段代码构造的计算图之后每次inference.update都会计算一次，其核心在于`copy`函数，\n",
    "该函数在带`dict_swap`调用时把原模型计算图里的模型变量换成了近似分布的变量，见下面的代码文档中的例子：\n",
    "\n",
    "```\n",
    "  Examples\n",
    "  --------\n",
    "  >>> x = tf.constant(2.0)\n",
    "  >>> y = tf.constant(3.0)\n",
    "  >>> z = x * y\n",
    "  >>>\n",
    "  >>> qx = tf.constant(4.0)\n",
    "  >>> # The TensorFlow graph is currently\n",
    "  >>> # `x` -> `z` <- y`, `qx`\n",
    "  >>>\n",
    "  >>> # This adds a subgraph with newly copied nodes,\n",
    "  >>> # `qx` -> `copied/z` <- `copied/y`\n",
    "  >>> z_new = ed.copy(z, {x: qx})\n",
    "  >>>\n",
    "  >>> sess = tf.Session()\n",
    "  >>> sess.run(z)\n",
    "  6.0\n",
    "  >>> sess.run(z_new)\n",
    "  12.0\n",
    "  \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如此，我们分别查看损失函数的构造步骤，显然它想让p_log_prob最大化，可以看到\n",
    "\n",
    "```\n",
    "    for x in six.iterkeys(inference.data):\n",
    "      if isinstance(x, RandomVariable):\n",
    "        x_copy = copy(x, dict_swap, scope=scope)\n",
    "        p_log_prob[s] += tf.reduce_sum(\n",
    "            inference.scale.get(x, 1.0) * x_copy.log_prob(dict_swap[x]))\n",
    "\n",
    "```\n",
    "\n",
    "这段代码中`x`是可观测变量时，之前的代码会使得`dict_swap[x]`的值就是实际观测值。`x_copy`是从原模型计算图的模型变量`x`“copy”出来的。\n",
    "但显然，若计算固定的原计算图中的`log_prob`，则这与我们想优化的参数没有建立任何关系。这里这个`copy`把原模型的随机变量`x`依赖的原模型的随机参数\n",
    "换成了近似分布的随机参数。而近似分布的随机参数受近似分布的确定参数的控制，这些确定参数将被tensorflow以似然原则最优化。\n",
    "\n",
    "但如果我们不只是想近似直接产生出数据的那些随机参数或隐变量的分布时，这一结果也是有用的：\n",
    "\n",
    "```\n",
    "    for z, qz in six.iteritems(inference.latent_vars):\n",
    "      # Copy q(z) to obtain new set of posterior samples.\n",
    "      qz_copy = copy(qz, scope=scope)\n",
    "      dict_swap[z] = qz_copy.value()\n",
    "\n",
    "    for z in six.iterkeys(inference.latent_vars):\n",
    "      z_copy = copy(z, dict_swap, scope=scope)\n",
    "      p_log_prob[s] += tf.reduce_sum(\n",
    "          inference.scale.get(z, 1.0) * z_copy.log_prob(dict_swap[z]))\n",
    "```\n",
    "\n",
    "可以看到，求出最接近数据的那些随机参数或隐变量的近似分布后，我们可以调整决定这些随机参数的随机参数的近似分布，\n",
    "去使得拟合这些“低层”的随机参数的边缘分布。而“顶层”参数去拟合“低层”参数（最底层的是观测数据）和拟合数据一样使用似然准则，\n",
    "但这里不是用数据来计算对数似然而是用低层分布的采样值，显然，我们可以假设低层分布充分接近真实分布（因为低层训练不会受高层影响，\n",
    "而最底层的训练是基于实际数据的，可以看做最底层充分接近真实分布后倒数第二层开始充分接近真实分布..以此类推），这么看有点像BP算法。\n",
    "\n",
    "比如下图所示，隐变量X决定隐变量Y，Y决定可观测变量Z，Z有实现值dZ。则我们设近似Y的随机变量qY，\n",
    "并改变qY的参数pY去使得Z合成qY而不是Y时产生dZ的似然度最大。充分训练后qY的分布将逼近Y给定dZ时的边缘条件分布。\n",
    "然后我们采集qY足够多的样本dY来类似的训练近似X的随机变量qX。如此，最终qX，qY都会在我们给它们设定的分布下找到对真正的X,Y给定dZ的条件边缘分布。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

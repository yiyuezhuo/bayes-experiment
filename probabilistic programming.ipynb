{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 概率编程语言与库\n",
    "\n",
    "概率编程语言主要提供概率模型，特别是一般概率网络（如隐马尔科夫模型）的标准描述方法。然后在背后进行自动优化\n",
    "（如采用theano后端的theano，采用tensorflow后端的edward），模拟（MCMC之类的可以用在几乎所有推断问题上的算法肯定有优化实现）\n",
    "等，简化了概率建模的工作。\n",
    "\n",
    "下面summary如下知乎答案\n",
    "\n",
    "https://www.zhihu.com/question/59442141\n",
    "\n",
    "## Church\n",
    "\n",
    "http://projects.csail.mit.edu/church/wiki/Church\n",
    "\n",
    "是一个概率编程语言，不过好像没什么人用。都搜不出很多信息（和这个坑爹名字可能有关。。）\n",
    "\n",
    "## WebPPL\n",
    "\n",
    "http://webppl.org/\n",
    "\n",
    "看上去用来可视化，教学，演示还不错，对我们统计学内部使用还是另请高明吧。GitHub上才273个star。\n",
    "\n",
    "## Edward\n",
    "\n",
    "http://edwardlib.org/\n",
    "\n",
    "基于tensorflow，看样子功能很多，而且有2335个star在github上。不过其实不如看做tensorflow的库，那个语法。。。\n",
    "\n",
    "## BUGS\n",
    "\n",
    "http://www.mrc-bsu.cam.ac.uk/software/bugs/\n",
    "\n",
    "和Church一样是老牌项目，目测已经没有开发了。\n",
    "\n",
    "## PYMC3\n",
    "\n",
    "https://github.com/pymc-devs/pymc3\n",
    "\n",
    "基于theano，封装比Edward高一点，估计受比它star高好几倍那书加持很大。有2277个star。感觉开发比Edward活跃？\n",
    "\n",
    "## Stan\n",
    "\n",
    "http://mc-stan.org/\n",
    "\n",
    "主推MCMC算法的库，有R，Python与其同名语言的前端与C++的后端（当然这就意味着无法利用GPU加速）。一系列项目但star都没超过1000。\n",
    "开发感觉也不是很积极。\n",
    "\n",
    "看起来还是应该在PyMC3和Edward里选，虽然PyMC3有看过那本书的加成和语法上的加分。但听说Edward有30倍速度与更小的内存消耗，\n",
    "而且有更多的功能。语法虽然蹩脚，但tensorflow本身学习一下也不是没有意义。可以试试Edward，不行再上PyMC3。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import edward as ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train = np.load('data/celegans_brain.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from edward.models import Normal, Poisson\n",
    "\n",
    "N = x_train.shape[0]  # number of data points\n",
    "K = 3  # latent dimensionality\n",
    "\n",
    "z = Normal(loc=tf.zeros([N, K]), scale=tf.ones([N, K]))\n",
    "\n",
    "# Calculate N x N distance matrix.\n",
    "# 1. Create a vector, [||z_1||^2, ||z_2||^2, ..., ||z_N||^2], and tile\n",
    "# it to create N identical rows.\n",
    "xp = tf.tile(tf.reduce_sum(tf.pow(z, 2), 1, keep_dims=True), [1, N])\n",
    "# 2. Create a N x N matrix where entry (i, j) is ||z_i||^2 + ||z_j||^2\n",
    "# - 2 z_i^T z_j.\n",
    "xp = xp + tf.transpose(xp) - 2 * tf.matmul(z, z, transpose_b=True)\n",
    "# 3. Invert the pairwise distances and make rate along diagonals to\n",
    "# be close to zero.\n",
    "xp = 1.0 / tf.sqrt(xp + tf.diag(tf.zeros(N) + 1e3))\n",
    "\n",
    "x = Poisson(rate=xp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inference = ed.MAP([z], data={x: x_train})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [100%] ██████████████████████████████ Elapsed: 15s | Loss: 35759.867\n"
     ]
    }
   ],
   "source": [
    "inference.run(n_iter=2500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
